{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a5264-b003-4101-862f-45653f2aed1b",
   "metadata": {},
   "source": [
    "# How to write multi-batch `BatchRequest` - Inferred `Sql` Example\n",
    "* A `BatchRequest` facilitates the return of one or more `batch(es)` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_one_or_more_batches_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \n",
    "* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\n",
    "   1. Self-Initializing Expectations to estimate parameters\n",
    "   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\n",
    "   \n",
    "* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee54886b-4f88-46d9-9afe-dfd8bb061e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.yaml_handler import YAMLHandler\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "import os\n",
    "\n",
    "yaml = YAMLHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa243d2-6905-403a-b47a-d89ba834b951",
   "metadata": {},
   "source": [
    "* Load `DataContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b1854b-2a75-422e-83bb-5509d868e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: gx.DataContext = gx.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462320-d76e-492c-96fb-f0ff8f788851",
   "metadata": {},
   "source": [
    "## Sql Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04726",
   "metadata": {},
   "source": [
    "### Example Database\n",
    "\n",
    "Imagine we have a database of 1 table, with `yellow_tripdata_sample_2020`, corresponding to all 12 months' `taxi_trip` data for 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd29b60b-7e16-4978-acee-0dab368cde3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellow_tripdata_sample_2020']\n"
     ]
    }
   ],
   "source": [
    "# connect to postgres DB, and print the existing tables\n",
    "pg_hostname = os.getenv(\"GE_TEST_LOCAL_DB_HOSTNAME\", \"localhost\")\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://postgres:@{pg_hostname}/test_ci\"\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a4ace",
   "metadata": {},
   "source": [
    "## Example Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a29c",
   "metadata": {},
   "source": [
    "In our example, we add a Datasource named `taxi_multi_batch_sql_datasource` with 1 table. We also have a `InferredAssetSqlDataConnector` named `inferred_data_connector_multi_batch_asset`.\n",
    "\n",
    "The Dataconnector configuration also includes a `splitter_method` to split the table values into multiple batches. The splitter we use is `split_on_year_and_month`, which creates Batches according to the `pickup_datetime` column which of type `timestamp` in the database schema. \n",
    "\n",
    "\n",
    "Our configuration also includes `schema_name` that is defined as part of `introspection_directives`. For other options for the DataConnector configuration, including other `introspection_directives`, please refer to the **Appendix** below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84150f65-bbd6-4b45-95ab-9590a29f116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: SqlAlchemyExecutionEngine\n",
      "Data Connectors:\n",
      "\tinferred_data_connector_multi_batch_asset_split_on_date_time : InferredAssetSqlDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (1 of 1):\n",
      "\t\tyellow_tripdata_sample_2020 (3 of 12): [{'pickup_datetime': {'year': 2020, 'month': 1}}, {'pickup_datetime': {'year': 2020, 'month': 10}}, {'pickup_datetime': {'year': 2020, 'month': 11}}]\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n",
      "\tinferred_data_connector_single_batch_asset : InferredAssetSqlDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (1 of 1):\n",
      "\t\tyellow_tripdata_sample_2020 (1 of 1): [{}]\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7f87b72a8610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_sql_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SqlAlchemyExecutionEngine\",\n",
    "        \"connection_string\": CONNECTION_STRING,\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"inferred_data_connector_single_batch_asset\": {\n",
    "            \"class_name\": \"InferredAssetSqlDataConnector\",\n",
    "            \"introspection_directives\": {\"schema_name\": \"public\"},\n",
    "        },\n",
    "        \"inferred_data_connector_multi_batch_asset_split_on_date_time\": {\n",
    "            \"class_name\": \"InferredAssetSqlDataConnector\",\n",
    "            \"splitter_method\": \"split_on_year_and_month\",\n",
    "            \"splitter_kwargs\": {\n",
    "                \"column_name\": \"pickup_datetime\",\n",
    "            },\n",
    "            \"introspection_directives\": {\"schema_name\": \"public\"},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b519a93",
   "metadata": {},
   "source": [
    "We see we have successfully configured this because the output shows 1 data asset `yellow_tripdata_sample_2020` with 12 batches, each associated with a different month in our pickup_datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8426f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438146be",
   "metadata": {},
   "source": [
    "## BatchRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9c59",
   "metadata": {},
   "source": [
    "Single Batch returned by `inferred_data_connector_single_batch_asset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0453cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_single_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35df7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e74a05-3fd1-4e47-9105-b721dbcf3516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7f87b72a8130>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4fa5",
   "metadata": {},
   "source": [
    "Multi Batch returned by `by_pickup_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32dbac9-af5d-4677-98f9-f098ef091b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset_split_on_date_time\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a284bfd-00aa-4068-bc09-71c6dea627e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(\n",
    "    batch_request=multi_batch_batch_request\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf3e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7f87b74c4d30>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b70dcf10>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b704fdf0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b74d5b50>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b74c49a0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b74bf6d0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b74bf850>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b704ff10>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b74d55b0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b737e3a0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b4707730>,\n",
       " <great_expectations.core.batch.Batch at 0x7f87b71991c0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_batch_batch_list  # 12 batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790746ee",
   "metadata": {},
   "source": [
    "You can also get a single Batch from a multi-batch DataConnector by passing in a `data_connector_query`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16612bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset_split_on_date_time\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    data_connector_query={\n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 1}}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ef1b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(\n",
    "    batch_request=single_batch_batch_request_from_multi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c4e057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7f87b7083340>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list  # has a length of 1, as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8b6ac",
   "metadata": {},
   "source": [
    "Let's review our batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "229815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch_list[\n",
    "    0\n",
    "]  # our single filtered batch with 'batch_identifiers': {'pickup_datetime': '2020-01'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82c00a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '<great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7f87b7905190>',\n",
       " 'batch_request': {'datasource_name': 'taxi_multi_batch_sql_datasource',\n",
       "  'data_connector_name': 'inferred_data_connector_multi_batch_asset_split_on_date_time',\n",
       "  'data_asset_name': 'yellow_tripdata_sample_2020',\n",
       "  'data_connector_query': {'batch_filter_parameters': {'pickup_datetime': {'year': 2020,\n",
       "     'month': 1}}},\n",
       "  'limit': None,\n",
       "  'batch_spec_passthrough': None},\n",
       " 'batch_definition': {'datasource_name': 'taxi_multi_batch_sql_datasource',\n",
       "  'data_connector_name': 'inferred_data_connector_multi_batch_asset_split_on_date_time',\n",
       "  'data_asset_name': 'yellow_tripdata_sample_2020',\n",
       "  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}}},\n",
       " 'batch_spec': {'data_asset_name': 'yellow_tripdata_sample_2020',\n",
       "  'table_name': 'yellow_tripdata_sample_2020',\n",
       "  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}},\n",
       "  'type': 'table',\n",
       "  'data_asset_name_prefix': '',\n",
       "  'data_asset_name_suffix': '',\n",
       "  'include_schema_name': False,\n",
       "  'schema_name': 'public',\n",
       "  'splitter_method': 'split_on_year_and_month',\n",
       "  'splitter_kwargs': {'column_name': 'pickup_datetime'}},\n",
       " 'batch_markers': {'ge_load_time': '20220909T043744.774968Z'}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a6ef5",
   "metadata": {},
   "source": [
    "# Using auto-initializing `Expectations` to generate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe9c76",
   "metadata": {},
   "source": [
    "We will generate a `Validator` using our `multi_batch_batch_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "847ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(\n",
    "    batch_request=multi_batch_batch_request\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1eca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_suite = data_context.create_expectation_suite(\n",
    "    expectation_suite_name=\"example_sql_suite\", overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "852deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(\n",
    "    batch_list=multi_batch_batch_list, expectation_suite=example_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01a0e9",
   "metadata": {},
   "source": [
    "When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that rows below are all associated with `pickup_datetime` being `9` (September, 2020). This is because the datetime values are stored lexicographically, meaning `1` and `11`, `12` values will appear **before** `2` and `3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7d827-ed51-4f83-ac41-33ae58416ef1",
   "metadata": {},
   "source": [
    "For simplicity, let's get a `validator` with the December `Batch`, which is in index `\"3\"` (after `1`, `10`, `11`). Notice that we are also casting the value as a `list` using the square brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11b673bc-8583-4fc5-9aa0-db6ca62e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(\n",
    "    batch_list=[multi_batch_batch_list[3]], expectation_suite=example_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffe9cabd-b2bd-46de-9317-ba4e809342fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba457dcc0e46bbae4c2a2beac7a266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-15 12:20:27</td>\n",
       "      <td>2020-12-15 12:40:49</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>209</td>\n",
       "      <td>237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>26.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-28 12:51:25</td>\n",
       "      <td>2020-12-28 13:15:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>44.60</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-27 10:43:42</td>\n",
       "      <td>2020-12-27 10:51:05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-08 13:42:52</td>\n",
       "      <td>2020-12-08 13:54:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>229</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-19 11:56:43</td>\n",
       "      <td>2020-12-19 12:08:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0        2.0 2020-12-15 12:20:27 2020-12-15 12:40:49              4.0   \n",
       "1        2.0 2020-12-28 12:51:25 2020-12-28 13:15:12              1.0   \n",
       "2        2.0 2020-12-27 10:43:42 2020-12-27 10:51:05              1.0   \n",
       "3        2.0 2020-12-08 13:42:52 2020-12-08 13:54:45              1.0   \n",
       "4        2.0 2020-12-19 11:56:43 2020-12-19 12:08:43              1.0   \n",
       "\n",
       "   trip_distance  rate_code_id store_and_fwd_flag  pickup_location_id  \\\n",
       "0           5.76           1.0                  N                 209   \n",
       "1          11.64           1.0                  N                 161   \n",
       "2           1.22           1.0                  N                 163   \n",
       "3           1.84           1.0                  N                 137   \n",
       "4           1.55           1.0                  N                  24   \n",
       "\n",
       "   dropoff_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  237           1.0         21.0    0.0      0.5        2.50   \n",
       "1                  220           1.0         33.5    0.0      0.5        5.00   \n",
       "2                   48           1.0          7.0    0.0      0.5        2.06   \n",
       "3                  229           2.0          9.0    0.0      0.5        0.00   \n",
       "4                   74           1.0          9.5    0.0      0.5        2.58   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0           0.0                    0.3         26.80                   2.5  \n",
       "1           2.8                    0.3         44.60                   2.5  \n",
       "2           0.0                    0.3         12.36                   2.5  \n",
       "3           0.0                    0.3         12.30                   2.5  \n",
       "4           0.0                    0.3         12.88                   0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be66602",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they use a `RuleBasedProfiler` under-the-hood to calculate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9ad7",
   "metadata": {},
   "source": [
    "Let's say we don't know the min_value and max_value for `expect_column_median_to_be_between()` so we \"guess\" at the `min_value` and `max_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c74c48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(\n",
    "    batch_list=multi_batch_batch_list, expectation_suite=example_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b524a2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ccff8579ab472ab20154a250169729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1.75\n",
       "  },\n",
       "  \"success\": false,\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_median_to_be_between(\n",
    "    column=\"trip_distance\", min_value=0, max_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d096f",
   "metadata": {},
   "source": [
    "The observed value for our `yellow_tripdata_sample_2020` table where `trip_distance` is going to be `1.75`, which means the Expectation fails. We guessed wrong - but we can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5016d8",
   "metadata": {},
   "source": [
    "Now we run the same expectation again, but this time with `auto=True`. This means the `median` values are going to calculated across the `batch_list` associated with the `Validator` (ie 12 Batches for `yellow_tripdata_sample_2020`), which gives the min value of `1.6` and the max value of `1.99`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdd821c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6275abd6f45044c28349009e294c8891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Expectations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Profiling Dataset:         0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a4221169044ee982c2e1cab7af3db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"expectation_config\": {\n",
       "    \"expectation_type\": \"expect_column_median_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"strict_max\": false,\n",
       "      \"min_value\": 1.6,\n",
       "      \"column\": \"trip_distance\",\n",
       "      \"strict_min\": false,\n",
       "      \"max_value\": 1.99\n",
       "    },\n",
       "    \"meta\": {\n",
       "      \"auto_generated_at\": \"20220909T044852.642862Z\",\n",
       "      \"great_expectations_version\": \"0.15.22+3.g7ae9a4c03.dirty\"\n",
       "    }\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1.75\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c277",
   "metadata": {},
   "source": [
    "The `auto=True` will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.61`) and the Expectation will pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b938",
   "metadata": {},
   "source": [
    "You can now save the `ExpectationSuite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eba880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec631",
   "metadata": {},
   "source": [
    "### Running the `ExpectationSuite` against single `Batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477381f5",
   "metadata": {},
   "source": [
    "Now the ExpectationSuite we built using all batches can be used to validate single batches using a Checkpoint. For example, we can run this checkpoint on new data when it comes in next month. In our example, let's validate a different batch from February 2020, using the `ExpectationSuite` we built from `yellow_tripdata_sample_2020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "747dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset_split_on_date_time\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    data_connector_query={\n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 2}}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb93d87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"action_list\": [\n",
       "    {\n",
       "      \"name\": \"store_validation_result\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreValidationResultAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"store_evaluation_params\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"update_data_docs\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"UpdateDataDocsAction\",\n",
       "        \"site_names\": []\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"batch_request\": {},\n",
       "  \"class_name\": \"Checkpoint\",\n",
       "  \"config_version\": 1.0,\n",
       "  \"evaluation_parameters\": {},\n",
       "  \"module_name\": \"great_expectations.checkpoint\",\n",
       "  \"name\": \"my_checkpoint\",\n",
       "  \"profilers\": [],\n",
       "  \"runtime_configuration\": {},\n",
       "  \"validations\": [\n",
       "    {\n",
       "      \"batch_request\": {\n",
       "        \"datasource_name\": \"taxi_multi_batch_sql_datasource\",\n",
       "        \"data_connector_name\": \"inferred_data_connector_multi_batch_asset_split_on_date_time\",\n",
       "        \"data_asset_name\": \"yellow_tripdata_sample_2020\",\n",
       "        \"data_connector_query\": {\n",
       "          \"batch_filter_parameters\": {\n",
       "            \"pickup_datetime\": {\n",
       "              \"year\": 2020,\n",
       "              \"month\": 2\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      },\n",
       "      \"expectation_suite_name\": \"example_sql_suite\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": single_batch_batch_request_from_multi,\n",
    "            \"expectation_suite_name\": \"example_sql_suite\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3269dfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed53cf5befc455f9de5e828c85d10b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = data_context.run_checkpoint(checkpoint_name=\"my_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6234082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914725d-85cc-4c9d-a93d-2d1c329eac74",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39f974",
   "metadata": {},
   "source": [
    "## Other Parameters for `InferredAssetSqlDataConnector`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec10bc",
   "metadata": {},
   "source": [
    "The signature of the `InferredAssetSqlDataConnector` also contains the following required parameters:\n",
    "- `name`: string describing the name of this DataConnector.\n",
    "- `datasource_name`: the name of the Datasource that contains it.\n",
    "- `execution_engine`: the type of ExecutionEngine to use.\n",
    "\n",
    "And the following optional parameters\n",
    "- `data_asset_name_prefix`: string describing an optional prefix to prepend to inferred data_asset_names.\n",
    "- `data_asset_name_suffix`: string describing an optional suffix to append to inferred data_asset_names.\n",
    "- `include_schema_name`: bool which answers the question : \"Should the data_asset_name include the schema as a prefix?\"\n",
    "- `splitter_method`: string that names method to split the target table into multiple `Batches`.\n",
    "- `splitter_kwargs`: dict containing keyword arguments to pass to `splitter_method`.\n",
    "- `sampling_method`: string that names method to sample `Batches`.\n",
    "- `sampling_kwargs`: dict containing keyword arguments to pass to `sampling_method`.\n",
    "- `excluded_tables`: A list of tables to ignore when inferring data asset_names\n",
    "- `included_tables`: If not `None`, only include tables in this list when inferring data asset_names.\n",
    "- `skip_inapplicable_tables`:  If `True`, tables that can't be successfully queried using sampling and splitter methods are excluded from inferred data_asset_names. If `False`, the class will throw an error during initialization if any such tables are encountered.\n",
    "- `batch_spec_passthrough`: dictionary with keys that will be added directly to batch_spec.\n",
    "- `introspection_directives`: Arguments passed to the introspection method to guide introspection.\n",
    "\n",
    "Valid keys for `introspection_directives` include: \n",
    "- `schema_name`: string describing schema to introspect (default is `None`). We used this parameter in our example above. \n",
    "- `ignore_information_schemas_and_system_tables`: bool (`default=True`) which determines whether to ignore information schemas and system tables when introspecting the database.\n",
    "- `system_tables`: optional list of strings that define `system_tables` for your db. \n",
    "- `information_schemas`: optional list of strings that define `information_schemas` for your db. \n",
    "- `include_views`: bool (`default=True`) which determines whether to include `views` when introspecting the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee136e6b",
   "metadata": {},
   "source": [
    "## Loading Data into Postgresql Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a183e-f0df-40f4-b64f-439666e32ab4",
   "metadata": {},
   "source": [
    "* The following code can be used to build the postgres database used in this notebook. It is included (and commented out) for reference.\n",
    "* In order to load the data into a local `postgresql` database, please feel free to use the `docker-compose.yml` file available at `great_expectations/assets/docker/postgresql/`. \n",
    "\n",
    "### To spin up the `postgresql` database\n",
    "* Have [Docker Desktop](https://www.docker.com/products/docker-desktop/) running locally.\n",
    "* Navigate to `great_expectations/assets/docker/postgresql/`\n",
    "* Type `docker-compose up`\n",
    "* Then uncomment and run the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad91c234-06a2-4e98-9d90-c999c2aad07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv']\n"
     ]
    }
   ],
   "source": [
    "# from tests.test_utils import load_data_into_test_database\n",
    "# from typing import List\n",
    "# import sqlalchemy as sa\n",
    "# import pandas as pd\n",
    "# pg_hostname = os.getenv(\"GE_TEST_LOCAL_DB_HOSTNAME\", \"localhost\")\n",
    "# CONNECTION_STRING = f\"postgresql+psycopg2://postgres:@{pg_hostname}/test_ci\"\n",
    "\n",
    "# data_paths: List[str] = [\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# engine = sa.create_engine(CONNECTION_STRING)\n",
    "# connection = engine.connect()\n",
    "# table_name = \"yellow_tripdata_sample_2020\"\n",
    "# res = connection.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "# for data_path in data_paths:\n",
    "#     # This utility is not for general use. It is only to support testing.\n",
    "#     load_data_into_test_database(\n",
    "#         table_name=\"yellow_tripdata_sample_2020\",\n",
    "#         csv_path=data_path,\n",
    "#         connection_string=CONNECTION_STRING,\n",
    "#         load_full_dataset=True,\n",
    "#         drop_existing_table=False,\n",
    "#         convert_colnames_to_datetime=[\"pickup_datetime\", \"dropoff_datetime\"]\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
