{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834eb3b0",
   "metadata": {},
   "source": [
    "# How to use `DataAssistants` - Spark\n",
    "\n",
    "* A `DataAssistant` enables you to quickly profile your data by providing a thin API over a pre-constructed `RuleBasedProfiler` configuration.\n",
    "* As a result of the profiling, you get back a result object consisting of \n",
    "    * `Metrics` that describe the current state of the data\n",
    "    * `Expectations` that are able to alert you if the data deviates from the expected state in the future. \n",
    "    \n",
    "* `DataAssistant` results can also be plotted to help you understand their data visually.\n",
    "* There are multiple `DataAssistants` centered around a theme (volume, nullity, etc), and this notebook walks you through an example `OnboardingDataAssistant`, which is the most general and extensive `DataAssistant`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3aab6",
   "metadata": {},
   "source": [
    "The `OnboardingDataAssistant` is considered to be the \"starting point\" for profiling and is generally applicable for numerical, categorial, or datetime data.  In our example we will be using `taxi_trip` data, building our `ExpectationSuite` using data from 2019, and validating the suite on January 2020 data, to see if our more-recent data falls within the range of previous months.\n",
    "\n",
    "In our example, the `OnboardingDataAssistant` will take in a `batch_request` describing data from 2019 and calculating upper and lower bounds for the following `Expectations` across the sample `Batches`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8362d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.core import ExpectationSuite\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.validator.validator import Validator\n",
    "from great_expectations.rule_based_profiler.data_assistant import (\n",
    "    DataAssistant,\n",
    "    OnboardingDataAssistant,\n",
    ")\n",
    "from great_expectations.rule_based_profiler.data_assistant_result import (\n",
    "    OnboardingDataAssistantResult,\n",
    ")\n",
    "from typing import List\n",
    "from ruamel import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5289b",
   "metadata": {},
   "source": [
    "### Example Directory\n",
    "\n",
    "Imagine we have a directory of 24 csv files, each corresponding to 1 month of NYC taxi rider data from 2019 to 2020.\n",
    "\n",
    "```\n",
    "\n",
    "yellow_tripdata_sample_2019-01.csv\n",
    "yellow_tripdata_sample_2019-02.csv\n",
    "yellow_tripdata_sample_2019-03.csv\n",
    "yellow_tripdata_sample_2019-04.csv\n",
    "yellow_tripdata_sample_2019-05.csv\n",
    "yellow_tripdata_sample_2019-06.csv\n",
    "yellow_tripdata_sample_2019-07.csv\n",
    "yellow_tripdata_sample_2019-08.csv\n",
    "yellow_tripdata_sample_2019-09.csv\n",
    "yellow_tripdata_sample_2019-10.csv\n",
    "yellow_tripdata_sample_2019-11.csv\n",
    "yellow_tripdata_sample_2019-12.csv\n",
    "yellow_tripdata_sample_2020-01.csv\n",
    "yellow_tripdata_sample_2020-02.csv\n",
    "yellow_tripdata_sample_2020-03.csv\n",
    "yellow_tripdata_sample_2020-04.csv\n",
    "yellow_tripdata_sample_2020-05.csv\n",
    "yellow_tripdata_sample_2020-06.csv\n",
    "yellow_tripdata_sample_2020-07.csv\n",
    "yellow_tripdata_sample_2020-08.csv\n",
    "yellow_tripdata_sample_2020-09.csv\n",
    "yellow_tripdata_sample_2020-10.csv\n",
    "yellow_tripdata_sample_2020-11.csv\n",
    "yellow_tripdata_sample_2020-12.csv\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc0ab6",
   "metadata": {},
   "source": [
    "## Set-up: Importing `pyspark`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea8376",
   "metadata": {},
   "source": [
    "Spark can be imported into your python environment in a number of ways, and the `findspark` package could be helpful in simplifying the process of importing the `pyspark` package in your python environment. \n",
    "\n",
    "More information can be found in the [project's website](https://github.com/minrk/findspark). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea10d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark: SparkSession = (\n",
    "    SparkSession.builder.appName(\"Python Spark SQL basic example\")\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c07eb",
   "metadata": {},
   "source": [
    "## Set-up: Importing Data and Setting up `schema`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73533fff",
   "metadata": {},
   "source": [
    "In order for `DataAssistants` to accurately configure Expectations for your data, there may be a need to explicitly define a `schema` as a `StructType()`. \n",
    "\n",
    "In the case of `taxi_data`, using `inferSchema` to detect the column types will result in an inaccurate detection of `timestamp`. Notice that `pickup_datetime` and `dropoff_datetime` columns are defined as `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4680225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name: str = (\n",
    "    \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2019-01.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ecc3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .load(file_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fa3702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rate_code_id: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0038c32",
   "metadata": {},
   "source": [
    "* To ensure that `DataAssistants` are able to correctly configure Expectations for `timestamp` columns, we will define our `schema` explicitly using the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27407161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    TimestampType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8c81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    "    TimestampType,\n",
    ")\n",
    "\n",
    "schema: StructType = StructType(\n",
    "    [\n",
    "        StructField(\"vendor_id\", IntegerType(), True),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "        StructField(\"passenger_count\", IntegerType(), True),\n",
    "        StructField(\"trip_distance\", DoubleType(), True),\n",
    "        StructField(\"rate_code_id\", IntegerType(), True),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "        StructField(\"pickup_location_id\", IntegerType(), True),\n",
    "        StructField(\"dropoff_location_id\", IntegerType(), True),\n",
    "        StructField(\"payment_type\", IntegerType(), True),\n",
    "        StructField(\"fare_amount\", DoubleType(), True),\n",
    "        StructField(\"extra\", DoubleType(), True),\n",
    "        StructField(\"mta_tax\", DoubleType(), True),\n",
    "        StructField(\"tip_amount\", DoubleType(), True),\n",
    "        StructField(\"tolls_amount\", DoubleType(), True),\n",
    "        StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "        StructField(\"total_amount\", DoubleType(), True),\n",
    "        StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a6073",
   "metadata": {},
   "source": [
    "## Set-up: Adding `taxi_data` `Datasource`\n",
    "In our example, we add a `Datasource` named `taxi_data` with 2 data_assets, `yellow_tripdata_2019` and `yellow_tripdata_2020`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731942e",
   "metadata": {},
   "source": [
    "**Where do we pass in the `schema`?**\n",
    "\n",
    "The `schema` defined above, along with other options for `spark.read()` function, can be passed in through the `batch_spec_passthrough` parameter. \n",
    "\n",
    "The `batch_spec_passthrough` parameter can either be defined at the\n",
    "- `DataConnector`-level\n",
    "- `Asset`-level \n",
    "- `BatchRequest`-level.\n",
    "\n",
    "\n",
    "And can be used to pass in `reader_method` (`csv`), or `reader_options` like (`header = True`)\n",
    "\n",
    "```python\n",
    "\"batch_spec_passthrough\":{\n",
    "    \"reader_method\": \"csv\",\n",
    "    \"reader_options\":{\n",
    "        \"header\": True,\n",
    "        \"schema\": schema # the schema we defined earlier\n",
    "    }\n",
    "```\n",
    "\n",
    "For our example we will be defining the `batch_spec_passthrough` parameter at the `BatchRequest`-level meaning we won't be including it at the `DataConnector`-level or `Asset`-level (which require an additional step). Those configurations can be found in the **Appendix** below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dcee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: gx.DataContext = gx.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29fd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: SparkDFExecutionEngine\n",
      "Data Connectors:\n",
      "\tconfigured_data_connector_multi_batch_asset : ConfiguredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (2 of 2):\n",
      "\t\tyellow_tripdata_2019 (3 of 12): ['yellow_tripdata_sample_2019-01.csv', 'yellow_tripdata_sample_2019-02.csv', 'yellow_tripdata_sample_2019-03.csv']\n",
      "\t\tyellow_tripdata_2020 (3 of 12): ['yellow_tripdata_sample_2020-01.csv', 'yellow_tripdata_sample_2020-02.csv', 'yellow_tripdata_sample_2020-03.csv']\n",
      "\n",
      "\tUnmatched data_references (3 of 104):['.DS_Store', 'first_3_files', 'first_3_files/.DS_Store']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7f9976336a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path: str = \"../../../../test_sets/taxi_yellow_tripdata_samples\"\n",
    "\n",
    "datasource_config: dict = {\n",
    "    \"name\": \"taxi_data\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SparkDFExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"configured_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"ConfiguredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"assets\": {\n",
    "                \"yellow_tripdata_2019\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2019)-(\\\\d.*)\\\\.csv\",\n",
    "                },\n",
    "                \"yellow_tripdata_2020\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2020)-(\\\\d.*)\\\\.csv\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be45bda",
   "metadata": {},
   "source": [
    "We see we have successfully configured this because the output shows 2 data assets `yellow_tripdata_sample_2019` and `yellow_tripdata_sample_2020` with 12 batches, each associated with a different filename. These become our `batch_identifiers` that distinguish one `Batch` from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0be5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa73e4",
   "metadata": {},
   "source": [
    "#  Configure `BatchRequest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e86821",
   "metadata": {},
   "source": [
    "In this example, we will be using a `BatchRequest` that will return all 12 batches of data from the `yellow_tripdata_sample_2019_data` table.  We will refer to the `Datasource` and `DataConnector` configured in the previous step. \n",
    "\n",
    "We also include the `batch_spec_passthrough` parameter with the `reader_method` and `reader_options` defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b790e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_data\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_2019\",\n",
    "    batch_spec_passthrough={\n",
    "        \"reader_method\": \"csv\",\n",
    "        \"reader_options\": {\"header\": True, \"schema\": schema},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5b6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request: BatchRequest = multi_batch_batch_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f09894b-8b27-4159-ad7c-ea786b9da396",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d564f515-ff0d-4218-b568-542e83fa6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7f9976299a00>,\n",
       " <great_expectations.core.batch.Batch at 0x7f9976503910>,\n",
       " <great_expectations.core.batch.Batch at 0x7f99763f8910>,\n",
       " <great_expectations.core.batch.Batch at 0x7f99762a35b0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f997653cbb0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f997653cbe0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f9976543730>,\n",
       " <great_expectations.core.batch.Batch at 0x7f997653ca60>,\n",
       " <great_expectations.core.batch.Batch at 0x7f997653c8b0>,\n",
       " <great_expectations.core.batch.Batch at 0x7f997653c040>,\n",
       " <great_expectations.core.batch.Batch at 0x7f9976503b50>,\n",
       " <great_expectations.core.batch.Batch at 0x7f9976333250>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list  # len = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a38c3a",
   "metadata": {},
   "source": [
    "# Run the `OnboardingDataAssistant`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b2796",
   "metadata": {},
   "source": [
    "* The `OnboardingDataAssistant` can be run directly from the `DataContext` by specifying `assistants` and `onboarding`, and passing in the `BatchRequest` from the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf15e6",
   "metadata": {},
   "source": [
    "**Note**: In the simplest way that we can run this is just by passing in our `batch_request` from our previous step, which corresponds to 2019 data. The appendix will show how the run can be further configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608bf80",
   "metadata": {},
   "source": [
    "If you would like to see the `ExpectationSuite` that was generated, then you can run the `get_expectation_suite()` method on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9bd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_context.assistants.onboarding.run(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80345d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_suite = result.get_expectation_suite(expectation_suite_name=\"temp_suite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6646fd0b",
   "metadata": {},
   "source": [
    "# Explore `DataAssistantResult` by plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c28857",
   "metadata": {},
   "source": [
    "The resulting `DataAssistantResult` can be explored by Plotting. The `plot_metrics()` function will plot the statistical metrics, and `plot_expectations_and_metrics()` will plot the generated min and max values overlayed on the statistical metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd4c66e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "            span.vega-bind-name {\n",
       "                color: #8784FF;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            form.vega-bindings {\n",
       "                color: #1B2A4D;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                position: absolute;\n",
       "                left: 75px;\n",
       "                top: 28px;\n",
       "            }\n",
       "            </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "            .widget-inline-hbox .widget-label {\n",
       "                color: #8784FF;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .widget-dropdown > select {\n",
       "                padding-right: 21px;\n",
       "                padding-left: 3px;\n",
       "                color: #1B2A4D;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                height: 20px;\n",
       "                line-height: 14px;\n",
       "                background-size: 20px;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baab0454933c46c0b9b90fdae53bac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Plot Type: ', layout=Layout(margin='0px', width='max-conten…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03353ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "            span.vega-bind-name {\n",
       "                color: #8784FF;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            form.vega-bindings {\n",
       "                color: #1B2A4D;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                position: absolute;\n",
       "                left: 75px;\n",
       "                top: 28px;\n",
       "            }\n",
       "            </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "            .widget-inline-hbox .widget-label {\n",
       "                color: #8784FF;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .widget-dropdown > select {\n",
       "                padding-right: 21px;\n",
       "                padding-left: 3px;\n",
       "                color: #1B2A4D;\n",
       "                font-family: Verdana;\n",
       "                font-size: 14px;\n",
       "                height: 20px;\n",
       "                line-height: 14px;\n",
       "                background-size: 20px;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2399dd275bf44408f1640cbae360de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Plot Type: ', layout=Layout(margin='0px', width='max-conten…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.plot_expectations_and_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437017f",
   "metadata": {},
   "source": [
    "# Save `ExpectationSuite`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b0dbc",
   "metadata": {},
   "source": [
    "Next, we can save the `ExpectationConfiguration` object resulting from the `DataAssistant` by:\n",
    "\n",
    "1. Creating an `ExpectationSuite`, which is `taxi_data_2019_suite` in our example\n",
    "2. Adding `ExpectationConfiguration` to the `ExpectationSuite`\n",
    "3. Saving the `ExpectationSuite` using `DataContext`'s `save_expectation_suite()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4db1dfc-defd-4b83-bc65-0e77ccd67cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite: ExpectationSuite = ExpectationSuite(\n",
    "    expectation_suite_name=\"taxi_data_2019_suite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaf5d924-1c10-4eab-b6ed-2063d0a73871",
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_configurations: List[\n",
    "    ExpectationConfiguration\n",
    "] = suite.add_expectation_configurations(\n",
    "    expectation_configurations=result.expectation_configurations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9426227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context.add_expectation_suite(expectation_suite=suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e916a0f-f68a-4221-a66a-5f9919bfa538",
   "metadata": {},
   "source": [
    "#  Running Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1550b",
   "metadata": {},
   "source": [
    "We have just trained our Expectation Suite on the 2019 data. Now we will run a validation using this ExpectationSuite on data from January of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd07f43-53ce-4a32-8e03-d0e2322ecc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_data\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_2020\",\n",
    "    data_connector_query={\"batch_filter_parameters\": {\"year\": \"2020\", \"month\": \"01\"}},\n",
    "    batch_spec_passthrough={\n",
    "        \"reader_method\": \"csv\",\n",
    "        \"reader_options\": {\n",
    "            \"header\": True,\n",
    "            \"schema\": schema,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65ab5c11-9716-4a39-88df-6f805d65eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f5c4c37-684b-4b94-b0ea-2ae7dec1884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasource_name': 'taxi_data', 'data_connector_name': 'configured_data_connector_multi_batch_asset', 'data_asset_name': 'yellow_tripdata_2020', 'batch_identifiers': {'year': '2020', 'month': '01'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list[0].batch_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3153f",
   "metadata": {},
   "source": [
    "Our `SimpleCheckpoint` configuration includes our `batch_request` and `ExpectationSuiteName` (which is `taxi_data_suite` in our example)\n",
    "\n",
    "We also include the `UpdateDataDocsAction`, so we can visualize the results of our Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c540fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_config: dict = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": single_batch_batch_request,\n",
    "            \"expectation_suite_name\": \"taxi_data_2019_suite\",\n",
    "        }\n",
    "    ],\n",
    "    \"action_list\": [\n",
    "        {\n",
    "            \"name\": \"update_data_docs\",\n",
    "            \"action\": {\n",
    "                \"class_name\": \"UpdateDataDocsAction\",\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "checkpoint_config_added = data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_context.run_checkpoint(checkpoint_name=\"my_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a18e22",
   "metadata": {},
   "source": [
    "### Examine results by looking at DataDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353ea25",
   "metadata": {},
   "source": [
    "We can check the results by evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfc2cc49-cd02-44db-9079-d0baed7ffe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189c83d",
   "metadata": {},
   "source": [
    "As you can see the results of the `Checkpoint` were not successful, which means the January 2020 data did not fall within the ranges predicted by the 2019 data. To examine this more closely, you can [open Data Docs here](great_expectations/uncommitted/data_docs/local_site/index.html). If the link doesn't work, from the location where this Notebook is located, you can go to `great_expectations/uncommitted/data_docs/local_site/index.html`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7f096-5b28-4a0a-81c1-829d57c9be23",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff94a73-740a-4a1d-b5cc-636ae6226cb5",
   "metadata": {},
   "source": [
    "## What Expectation are included in the `OnboardingDataAssistant`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e3e3",
   "metadata": {},
   "source": [
    "The `OnboardingDataAssistant` is built with the following `Rules` that are run internally by the `RuleBasedProfiler`. \n",
    "\n",
    "- `TableRule`\n",
    "- `Column Uniqueness and Nullity Rules`\n",
    "- `NumericColumnRule`\n",
    "- `DateColumnRule`\n",
    "- `TextColumnRule`\n",
    "- `CategoricalColumnRule`\n",
    "\n",
    "\n",
    "#### Table Rule\n",
    "This Rule will take the data as a table and try to calculate the following parameter values for Expectations across batches that we pass in. \n",
    "\n",
    "* `expect_table_row_count_to_be_between`: \n",
    "    - `min_value` : maximum threshold for table row count.\n",
    "    - `max_value` : minimum threshold for table row count.\n",
    "* `expect_table_columns_to_match_set`:\n",
    "    - `column_set`: Either a list or set of strings, that describe the columns of the Table\n",
    "    - `exact_match`: Boolean (`default=True`) which determines whether the list of columns must exactly match the observed columns. \n",
    "    \n",
    "#### Rules for Uniqueness, Nullity and Non-nullity\n",
    "These `Rules` each have 1 `Expectations` associated with them, and will be used by the `DataAssistant` to generate `ExpectationConfigurations` for the following `Expectations` for each column in our data. \n",
    "\n",
    "* `expect_column_values_to_be_unique`\n",
    "* `expect_column_values_to_be_null`\n",
    "* `expect_column_values_to_not_be_null`\n",
    " \n",
    "They each take 2 parameters. `column`, which is the name of the column being validated, and `mostly`, which is an optional `float` value between `0.0` and `1.0` which specifies the fraction of values that match the expectation. Default for the `DataAssistant` is `1.0`. \n",
    "\n",
    "#### NumericColumnRule\n",
    "The `NumericColumnRule` will calculate the `min_value` and `max_value` for the following expectations. \n",
    "\n",
    "* `expect_column_min_to_be_between`\n",
    "* `expect_column_max_to_be_between`\n",
    "* `expect_column_values_to_be_between`\n",
    "* `expect_column_median_to_be_between`\n",
    "* `expect_column_mean_to_be_between`\n",
    "* `expect_column_stdev_to_be_between`\n",
    "\n",
    "The estimation will be done by the `exact` estimator by default, which takes in the values across all Batches in the batch list (in our example 12 months of data from 2019).\n",
    "\n",
    "If you do `data_assistant.run()` with the `estimator` parameter set to `drop_outliers` then `bootstrapping` will be done behind-the-scenes to estimate outliers.\n",
    "\n",
    "The parameters for `bootstrapping` are:\n",
    "\n",
    "* `n_resamples` : It is set by default to `9999` which is the default in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.htm\n",
    "\n",
    "* `false_positive_rate`: A user-configured fraction between 0 and 1 expressing desired false positive rate for\n",
    "    identifying unexpected values as judged by the upper- and lower- quantiles of the observed metric data. Set by default to be `0.05`.\n",
    "* `random_seed`: Seed for randomization. If omitted (which is the default), then we use `np.random.choice`. otherwise, we use `np.random.Generator(np.random.PCG64(random_seed))`.\n",
    "* `round_decimals`: A user-configured non-negative integer indicating the number of decimals of\n",
    "    rounding precision of the computed parameter values (i.e., `min_value`, `max_value`) prior to packaging them\n",
    "    on output. For `NumericColumnRule` the default is `15` which means calculations are done 15 digits after the decimal point.\n",
    "* `mostly`: is `1.0` by default\n",
    "* `strict_min` and `strict_max` are `False`, and these are parameters that determine whether the minimum proportion of unique values must be strictly smaller than max or min value.\n",
    "* `truncate_values`:  User-configured directive for whether or not to allow the computed parameter values (i.e.,`lower_bound`, `upper_bound`) to take on values outside the specified bounds when packaged on output\n",
    "* `allow_relative_error`:  Whether to allow relative error in quantile communications on backends that support or require it.\n",
    "\n",
    "In addition, the `expect_column_quantile_values_to_be_between` Expectation takes in the following parameters: \n",
    "\n",
    "* `quantiles` : Quantiles and associated value ranges for the column, with the default being`[0.25, 0.5, 0.75]`\n",
    "* `quantile_statistic_interpolation_method`: which is used when estimating quantile values. Recognized values include `auto`, `nearest`, and `linear`. (default is `nearest`).\n",
    "* `quantile_bias_correction`: Used when determining whether to correct for quantile bias. Recognized values are `True` and  `False` with default being `False`.\n",
    "* `quantile_bias_std_error_ratio_threshold`: If omitted\n",
    "    (default), then 0.25 is used (as minimum ratio of bias to standard error for applying bias correction).\n",
    "* `include_estimator_samples_histogram_in_details`: Determines whether the estimator samples are included in the results. (default is `False`).\n",
    "  \n",
    "\n",
    "#### DateColumnRules\n",
    "The `DateColumnRule` will take a `datetime` column and calculate the `min_value` and `max_value` for the following Expectations.\n",
    "\n",
    "* `expect_column_min_to_be_between`\n",
    "* `expect_column_max_to_be_between`\n",
    "* `expect_column_values_to_be_between`\n",
    "\n",
    "The estimation will be done by the `exact` estimator by default, which takes in the values across all Batches in the batch list (in our example 12 months of data from 2019).\n",
    "\n",
    "If you do `data_assistant.run()` with the `estimator` parameter set to `drop_outliers` then `bootstrapping` will be done behind-the-scenes to estimate outliers.\n",
    "\n",
    "The parameters for `bootstrapping` are:\n",
    "\n",
    "* `n_resamples` : For bootstrapping. It is set by default to `9999` which is the default in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.htm\n",
    "* `false_positive_rate`: user-configured fraction between 0 and 1 expressing desired false positive rate for\n",
    "    identifying unexpected values as judged by the upper- and lower- quantiles of the observed metric data. Default is `0.05`.\n",
    "* `random_seed`: Seed for randomization. If omitted (which is the default), then we use `np.random.choice`. otherwise, we use `np.random.Generator(np.random.PCG64(random_seed))`.\n",
    "* `round_decimals` A user-configured non-negative integer indicating the number of decimals of the\n",
    "    rounding precision of the computed parameter values (i.e., `min_value`, `max_value`) prior to packaging them\n",
    "    on output. Default for `DateColumnRules` is  `1` which means calculations are done 1 digit after the decimal point\n",
    "\n",
    "\n",
    "#### TextColumnsRule\n",
    "\n",
    "The `TextColumnRule` will generate parameters for the following 2 `Expectations`.\n",
    "\n",
    "* `expect_column_value_lengths_to_be_between`\n",
    "* `expect_column_values_to_match_regex`\n",
    "\n",
    "For `expect_column_value_lengths_to_be_between` will have the parameters `min_value` and `max_value` estimated. \n",
    "\n",
    "Estimation will be done using the `exact` estimator by default, but if you select `drop_outliers` then the following parameters are set by default for `bootstrap` estimation\n",
    "\n",
    "* `n_resamples` : For bootstrapping. It is set by default to `9999` which is the default in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html\n",
    "* `false_positive_rate`: user-configured fraction between 0 and 1 expressing desired false positive rate for\n",
    "    identifying unexpected values as judged by the upper- and lower- quantiles of the observed metric data. Default is `0.05`.\n",
    "* `random_seed`: Seed for randomization. If omitted (which is the default), then we use `np.random.choice`. otherwise, we use `np.random.Generator(np.random.PCG64(random_seed))`.\n",
    "* `round_decimals` A user-configured non-negative integer indicating the number of decimals of the\n",
    "    rounding precision of the computed parameter values (i.e., `min_value`, `max_value`) prior to packaging them\n",
    "    on output. Default for `TextColumnRule` is  `0` which means calculations are done to the nearest integer.\n",
    "    \n",
    "For `expect_column_values_to_match_regex`, the values in the column be matched against a candidate list of common `regex` values which were built from the following sources: \n",
    "\n",
    "   - [20 Most Common Regular Expressions](https://regexland.com/most-common-regular-expressions/)\n",
    "   - [Stackoverflow on how to test for valid uuid](https://stackoverflow.com/questions/7905929/how-to-test-valid-uuid-guid/13653180#13653180)\n",
    "\n",
    "* This is the regex list used by the `TextColumnsRule`.\n",
    "\n",
    "```python\n",
    "CANDIDATE_REGEX: Set[str] = {\n",
    "    r\"\\d+\",  # whole number with 1 or more digits\n",
    "    r\"-?\\d+\",  # negative whole numbers\n",
    "    r\"-?\\d+(?:\\.\\d*)?\",  # decimal numbers with . (period) separator\n",
    "    r\"[A-Za-z0-9\\.,;:!?()\\\"'%\\-]+\",  # general text\n",
    "    r\"^\\s+\",  # leading space\n",
    "    r\"\\s+$\",  # trailing space\n",
    "    r\"https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b(?:[-a-zA-Z0-9@:%_\\+.~#()?&//=]*)\",  # Matching URL (including http(s) protocol)\n",
    "    r\"<\\/?(?:p|a|b|img)(?: \\/)?>\",  # HTML tags\n",
    "    r\"(?:25[0-5]|2[0-4]\\d|[01]\\d{2}|\\d{1,2})(?:.(?:25[0-5]|2[0-4]\\d|[01]\\d{2}|\\d{1,2})){3}\",  # IPv4 IP address\n",
    "    r\"(?:[A-Fa-f0-9]){0,4}(?: ?:? ?(?:[A-Fa-f0-9]){0,4}){0,7}\",  # IPv6 IP address,\n",
    "    r\"\\b[0-9a-fA-F]{8}\\b-[0-9a-fA-F]{4}-[0-5][0-9a-fA-F]{3}-[089ab][0-9a-fA-F]{3}-\\b[0-9a-fA-F]{12}\\b \",  # UUID\n",
    "    }\n",
    "```\n",
    "\n",
    "**Note**: The above list can be found in the [great_expectations repo here](https://github.com/great-expectations/great_expectations/blob/da2376b613843844afc041538269bb7683444b1f/great_expectations/rule_based_profiler/parameter_builder/regex_pattern_string_parameter_builder.py#L38)\n",
    "\n",
    "#### CategoricalColumnsRule\n",
    "\n",
    "The CategoricalColumnsRule will generate parameters for the following 3 Expectations:\n",
    "\n",
    "* `expect_column_values_to_be_in_set`\n",
    "* `expect_column_unique_value_count_to_be_between`\n",
    "* `expect_column_proportion_of_unique_values_to_be_between`\n",
    "\n",
    "\n",
    "Categorical columns are determined to be ones that meet a certain cardinality threshold. This prevents us from calculating the number of `unique` value in a column with millions of rows, with each value being slightly different from another (which is theoretically possible). \n",
    "\n",
    "Great Expectations gets around this by only building the unique value set for columns that have less than a certain number of unique values, which is determined by the cardinality threshold. The default threshold is `FEW` which means Great Expectations will generate parameters for `expect_column_values_to_be_in_set()` for columns where the number of unique values are less than or equal to 100. \n",
    "\n",
    "Other values for cardinality values include: \n",
    "\n",
    "```python \n",
    "ZERO = AbsoluteCardinalityLimit(\"ZERO\", 0)\n",
    "ONE = AbsoluteCardinalityLimit(\"ONE\", 1)\n",
    "TWO = AbsoluteCardinalityLimit(\"TWO\", 2)\n",
    "VERY_FEW = AbsoluteCardinalityLimit(\"VERY_FEW\", 10)\n",
    "FEW = AbsoluteCardinalityLimit(\"FEW\", 100)\n",
    "SOME = AbsoluteCardinalityLimit(\"SOME\", 1000)\n",
    "MANY = AbsoluteCardinalityLimit(\"MANY\", 10000)\n",
    "VERY_MANY = AbsoluteCardinalityLimit(\"VERY_MANY\", 100000)\n",
    "UNIQUE = RelativeCardinalityLimit(\"UNIQUE\", 1.0)\n",
    "\n",
    "... # and more\n",
    "```\n",
    "\n",
    "The full list of cardinality values used by Great Expectations can be found in the [great_expectations repo here](https://github.com/great-expectations/great_expectations/blob/da2376b613843844afc041538269bb7683444b1f/great_expectations/rule_based_profiler/helpers/cardinality_checker.py#L55). \n",
    "\n",
    "The three Expectations each have their own parameters\n",
    "\n",
    "`expect_column_values_to_be_in_set` requires `column` (column name) and `value_set`, which is calculated for all columns that meet the cardinality threshold. \n",
    "\n",
    "`expect_column_unique_value_count_to_be_between` has `column` (column name) and `min_value` and `max_value`.\n",
    "\n",
    "Estimation will be done using the `exact` estimator by default, but if you select `drop_outliers` then the following parameters are set by default for `bootstrap` estimation\n",
    "\n",
    "* `n_resamples` : For bootstrapping. It is set by default to `9999` which is the default in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.htm\n",
    "* `false_positive_rate`: user-configured fraction between 0 and 1 expressing desired false positive rate for\n",
    "    identifying unexpected values as judged by the upper- and lower- quantiles of the observed metric data. Default is `0.05`.\n",
    "* `random_seed`: Seed for randomization. If omitted (which is the default), then we use `np.random.choice`. otherwise, we use `np.random.Generator(np.random.PCG64(random_seed))`.\n",
    "\n",
    "`expect_column_proportion_of_unique_values_to_be_between` has the following parameters\n",
    "   \n",
    "* `column`: column name\n",
    "* `min_value`:  minimum proportion of unique values, ranging from 0 to 1\n",
    "* `max_value`:  minimum proportion of unique values, ranging from 0 to 1\n",
    "* `strict_min`: determine whether the minimum proportion of unique values must be strictly greater than min value, with the `default=False`\n",
    "* `strict_max`: determine whether the minimum proportion of unique values must be strictly smaller than max value, with the `default=False`\n",
    "\n",
    "Estimation will be done using the `exact` estimator by default, but if you select `drop_outliers` then the following parameters are set by default for `bootstrap` estimation\n",
    "\n",
    "* `n_resamples` : For bootstrapping. It is set by default to `9999` which is the default in https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.htm\n",
    "* `false_positive_rate`: user-configured fraction between 0 and 1 expressing desired false positive rate for\n",
    "    identifying unexpected values as judged by the upper- and lower- quantiles of the observed metric data. Default is `0.05`.\n",
    "* `random_seed`: Seed for randomization. If omitted (which is the default), then then we use `np.random.choice`. otherwise, we use `np.random.Generator(np.random.PCG64(random_seed))`.\n",
    "* `round_decimals`: A user-configured non-negative integer indicating the number of decimals of the\n",
    "    rounding precision of the computed parameter values (i.e., `min_value`, `max_value`) prior to packaging them\n",
    "    on output. For `CategoricalColumnsRule` the default is `15` which means calculations are done 15 digits after the decimal point.\n",
    "* `mostly`: is `1.0` by default\n",
    "* `strict_min` and `strict_max` are `False`, and these are parameters that determine whether the minimum proportion of unique values must be strictly smaller than max or min value.\n",
    "* `truncate_values`:  User-configured directive for whether or not to allow the computed parameter values (i.e.,`lower_bound`, `upper_bound`) to take on values outside the specified bounds when packaged on output\n",
    "* `allow_relative_error`:  Whether to allow relative error in quantile communications on backends that support or require it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaca746",
   "metadata": {},
   "source": [
    "# Adjusting `DataAssistant` Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946defb",
   "metadata": {},
   "source": [
    "Now that you can run the profiler, you may want more control over the specifics of how the `DataAssistant` is run. \n",
    "\n",
    "The first major parameter that you may want to set is is `estimation`, which you will be inputting directly into the `run()` method.\n",
    "\n",
    "* if set to `flag_outliers` then the DataAssistant will use `bootstrapping` on the Batches returned by the `batch_request` to estimate outliers. The parameters will be `n_resamples`, `false_positive` rate etc with more details in the above section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code will run the onboarding assistant with bootstrapping\n",
    "data_context.assistants.onboarding.run(\n",
    "    batch_request=single_batch_batch_request, estimation=\"flag_outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac5be3",
   "metadata": {},
   "source": [
    "Now what if you need more granular control? For instance, how would you set the `cardinality_threshold` for the CategoricalColumnsRule. First you can see the full list of parameters that are passed into the DataAssistant by calling the `run` directly, with no parameters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a406851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function great_expectations.rule_based_profiler.data_assistant.data_assistant_runner.DataAssistantRunner.run_impl.<locals>.run(batch_request: Union[great_expectations.core.batch.BatchRequestBase, dict], estimation: Union[str, great_expectations.rule_based_profiler.data_assistant.data_assistant_runner.NumericRangeEstimatorType, NoneType] = 'exact', include_column_names: Union[str, List[str], NoneType] = None, exclude_column_names: Union[str, List[str], NoneType] = ['id'], include_column_name_suffixes: Union[str, Iterable, List[str], NoneType] = None, semantic_type_filter_module_name: Union[str, NoneType] = None, semantic_type_filter_class_name: Union[str, NoneType] = None, max_unexpected_values: Union[str, int] = 0, max_unexpected_ratio: Union[str, float, NoneType] = None, min_max_unexpected_values_proportion: Union[str, float, NoneType] = 0.975, allowed_semantic_types_passthrough: Union[str, great_expectations.rule_based_profiler.domain.SemanticDomainTypes, List[Union[str, great_expectations.rule_based_profiler.domain.SemanticDomainTypes]], NoneType] = ['logic'], cardinality_limit_mode: Union[str, great_expectations.rule_based_profiler.helpers.cardinality_checker.CardinalityLimitMode, dict, NoneType] = '$variables.cardinality_limit_mode', max_unique_values: Union[str, int, NoneType] = None, max_proportion_unique: Union[str, float, NoneType] = None, table_rule: dict = {'false_positive_rate': 0.05, 'estimator': 'bootstrap', 'n_resamples': 9999, 'random_seed': None, 'quantile_statistic_interpolation_method': 'nearest', 'quantile_bias_correction': False, 'quantile_bias_std_error_ratio_threshold': None, 'include_estimator_samples_histogram_in_details': False, 'truncate_values': {'lower_bound': 0, 'upper_bound': None}, 'round_decimals': 0, 'exact_match': None, 'success_ratio': 1.0}, column_value_uniqueness_rule: dict = {'success_ratio': 0.75}, column_value_nullity_rule: dict = {'success_ratio': 0.75}, column_value_nonnullity_rule: dict = {'success_ratio': 0.75}, numeric_columns_rule: dict = {'mostly': 1.0, 'strict_min': False, 'strict_max': False, 'quantiles': [0.25, 0.5, 0.75], 'allow_relative_error': False, 'false_positive_rate': 0.05, 'estimator': 'bootstrap', 'n_resamples': 9999, 'random_seed': None, 'quantile_statistic_interpolation_method': 'nearest', 'quantile_bias_correction': False, 'quantile_bias_std_error_ratio_threshold': None, 'include_estimator_samples_histogram_in_details': False, 'truncate_values': {'lower_bound': None, 'upper_bound': None}, 'round_decimals': 15}, datetime_columns_rule: dict = {'mostly': 1.0, 'strict_min': False, 'strict_max': False, 'false_positive_rate': 0.05, 'estimator': 'bootstrap', 'n_resamples': 9999, 'random_seed': None, 'quantile_statistic_interpolation_method': 'nearest', 'quantile_bias_correction': False, 'quantile_bias_std_error_ratio_threshold': None, 'include_estimator_samples_histogram_in_details': False, 'truncate_values': {'lower_bound': None, 'upper_bound': None}, 'round_decimals': 1}, text_columns_rule: dict = {'mostly': 1.0, 'strict_min': False, 'strict_max': False, 'false_positive_rate': 0.05, 'estimator': 'bootstrap', 'n_resamples': 9999, 'random_seed': None, 'quantile_statistic_interpolation_method': 'nearest', 'quantile_bias_correction': False, 'quantile_bias_std_error_ratio_threshold': None, 'include_estimator_samples_histogram_in_details': False, 'truncate_values': {'lower_bound': 0, 'upper_bound': None}, 'round_decimals': 0, 'success_ratio': 0.75}, categorical_columns_rule: dict = {'cardinality_limit_mode': 'FEW', 'mostly': 1.0, 'strict_min': False, 'strict_max': False, 'false_positive_rate': 0.05, 'estimator': 'bootstrap', 'n_resamples': 9999, 'random_seed': None, 'quantile_statistic_interpolation_method': 'nearest', 'quantile_bias_correction': False, 'quantile_bias_std_error_ratio_threshold': None, 'include_estimator_samples_histogram_in_details': False, 'truncate_values': {'lower_bound': 0.0, 'upper_bound': None}, 'round_decimals': 15}) -> great_expectations.rule_based_profiler.data_assistant_result.data_assistant_result.DataAssistantResult>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_context.assistants.onboarding.run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8edb40",
   "metadata": {},
   "source": [
    "If you look closely at the output, you will see that it is broken up into `rules` with one of the rules being the `categorical_columns_rule`. You'll see that it is type hinted as a `dict`. With parameters like `cardinality_limit_mode`, `mostly`, etc. \n",
    "\n",
    "```python\n",
    "categorical_columns_rule = {\n",
    "     'cardinality_limit_mode': 'FEW',\n",
    "     'mostly': 1.0,\n",
    "     'strict_min': False, \n",
    "     'strict_max': False, \n",
    "     'false_positive_rate': 0.05, \n",
    "     'estimator': 'bootstrap', \n",
    "     'n_resamples': 9999,\n",
    "     'random_seed': None, \n",
    "     'quantile_statistic_interpolation_method': 'nearest', \n",
    "     'quantile_bias_correction': False, \n",
    "     'quantile_bias_std_error_ratio_threshold': None,\n",
    "     'include_estimator_samples_histogram_in_details': False, \n",
    "     'truncate_values': {\n",
    "     'lower_bound': 0.0,\n",
    "       'upper_bound': None\n",
    "     }, \n",
    "    'round_decimals': 15\n",
    "  }\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9993a59",
   "metadata": {},
   "source": [
    "If you copy the dictionary and set the key-value pair you are interested in, then `categorical_columns_rule` can be passed into the `assistants.onboarding.run()` method as a dictionary. \n",
    "\n",
    "In the following example we have set the `cardinality_limit_mode` from `FEW` to `VERY_MANY` ([more information in the great_expectations repo here](https://github.com/great-expectations/great_expectations/blob/da2376b613843844afc041538269bb7683444b1f/great_expectations/rule_based_profiler/parameter_builder/regex_pattern_string_parameter_builder.py#L38)). The remaining parameters can either be kept or commented out. Both calls below will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d40c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will work\n",
    "data_context.assistants.onboarding.run(\n",
    "    batch_request=multi_batch_batch_request,\n",
    "    categorical_columns_rule={\n",
    "        \"cardinality_limit_mode\": \"VERY_MANY\",\n",
    "        #'mostly': 1.0,\n",
    "        #'strict_min': False,\n",
    "        #'strict_max': False,\n",
    "        #'false_positive_rate': 0.05,\n",
    "        #'estimator': 'bootstrap',\n",
    "        #'n_resamples': 9999,\n",
    "        #'random_seed': None,\n",
    "        #'quantile_statistic_interpolation_method': 'nearest',\n",
    "        #'quantile_bias_correction': False,\n",
    "        #'quantile_bias_std_error_ratio_threshold': None,\n",
    "        #'include_estimator_samples_histogram_in_details': False,\n",
    "        #'truncate_values': {\n",
    "        #    'lower_bound': 0.0,\n",
    "        #   'upper_bound': None\n",
    "        # },\n",
    "        #'round_decimals': 15\n",
    "    },\n",
    ")\n",
    "\n",
    "# and so will this\n",
    "data_context.assistants.onboarding.run(\n",
    "    batch_request=multi_batch_batch_request,\n",
    "    categorical_columns_rule={\n",
    "        \"cardinality_limit_mode\": \"VERY_MANY\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788358ff",
   "metadata": {},
   "source": [
    "# Alternate configurations of `batch_spec_passthrough` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b04f19",
   "metadata": {},
   "source": [
    "As mentioned in the previous section, options for `spark.read()` function, can be passed in through the `batch_spec_passthrough` parameter.\n",
    "\n",
    "The `batch_spec_passthrough` parameter can either be defined at the\n",
    "\n",
    "- `DataConnector`-level\n",
    "- `Asset`-level\n",
    "- `BatchRequest`-level.\n",
    "\n",
    "And can be used to pass in `reader_method` (csv), or `reader_options` like (`header = True`)\n",
    "\n",
    "```python\n",
    "\"batch_spec_passthrough\":{\n",
    "    \"reader_method\": \"csv\",\n",
    "    \"reader_options\":{\n",
    "        \"header\": True,\n",
    "        \"schema\": schema # the schema we defined earlier\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d1045",
   "metadata": {},
   "source": [
    "When loading in a `Datasource` configuration through ` data_context.add_datasource(**datasource_config)`, we need to serialize the `schema` by calling the `jsonValue()` function of the `StructType` object. [More information here.](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.types.StructType.html#pyspark.sql.types.StructType.jsonValue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cd53a",
   "metadata": {},
   "source": [
    "### `batch_spec_passthrough` defined at the `DataConnector`-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede6c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_config: dict = {\n",
    "    \"name\": \"taxi_data\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SparkDFExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"configured_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"ConfiguredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"batch_spec_passthrough\": {\n",
    "                \"reader_method\": \"csv\",\n",
    "                \"reader_options\": {\"header\": True, \"schema\": schema.jsonValue()},\n",
    "            },\n",
    "            \"assets\": {\n",
    "                \"yellow_tripdata_2019\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2019)-(\\\\d.*)\\\\.csv\",\n",
    "                },\n",
    "                \"yellow_tripdata_2020\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2020)-(\\\\d.*)\\\\.csv\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0c440",
   "metadata": {},
   "source": [
    "### `batch_spec_passthrough` defined at the `Asset`-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80e7d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_config: dict = {\n",
    "    \"name\": \"taxi_data\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SparkDFExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"configured_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"ConfiguredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"assets\": {\n",
    "                \"yellow_tripdata_2019\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2019)-(\\\\d.*)\\\\.csv\",\n",
    "                },\n",
    "                \"yellow_tripdata_2020\": {\n",
    "                    \"group_names\": [\"year\", \"month\"],\n",
    "                    \"pattern\": \"yellow_tripdata_sample_(2020)-(\\\\d.*)\\\\.csv\",\n",
    "                    \"batch_spec_passthrough\": {\n",
    "                        \"reader_method\": \"csv\",\n",
    "                        \"reader_options\": {\n",
    "                            \"header\": True,\n",
    "                            \"schema\": schema.jsonValue(),\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
